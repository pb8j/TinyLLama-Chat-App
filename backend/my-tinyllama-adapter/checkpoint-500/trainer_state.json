{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.2051282051282053,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0641025641025641,
      "grad_norm": 2.328521966934204,
      "learning_rate": 0.00019794871794871796,
      "loss": 3.1882,
      "step": 10
    },
    {
      "epoch": 0.1282051282051282,
      "grad_norm": 3.5311014652252197,
      "learning_rate": 0.0001953846153846154,
      "loss": 3.0601,
      "step": 20
    },
    {
      "epoch": 0.19230769230769232,
      "grad_norm": 4.099020957946777,
      "learning_rate": 0.0001930769230769231,
      "loss": 2.3725,
      "step": 30
    },
    {
      "epoch": 0.2564102564102564,
      "grad_norm": 4.363420009613037,
      "learning_rate": 0.00019051282051282052,
      "loss": 2.18,
      "step": 40
    },
    {
      "epoch": 0.32051282051282054,
      "grad_norm": 14.905647277832031,
      "learning_rate": 0.0001887179487179487,
      "loss": 1.9209,
      "step": 50
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 7.3962178230285645,
      "learning_rate": 0.00018615384615384617,
      "loss": 1.9867,
      "step": 60
    },
    {
      "epoch": 0.44871794871794873,
      "grad_norm": 6.935502052307129,
      "learning_rate": 0.00018358974358974358,
      "loss": 1.8397,
      "step": 70
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 8.669480323791504,
      "learning_rate": 0.00018102564102564104,
      "loss": 1.8604,
      "step": 80
    },
    {
      "epoch": 0.5769230769230769,
      "grad_norm": 6.227291584014893,
      "learning_rate": 0.00017846153846153847,
      "loss": 1.9167,
      "step": 90
    },
    {
      "epoch": 0.6410256410256411,
      "grad_norm": 7.613867282867432,
      "learning_rate": 0.0001758974358974359,
      "loss": 1.5592,
      "step": 100
    },
    {
      "epoch": 0.7051282051282052,
      "grad_norm": 6.775049686431885,
      "learning_rate": 0.00017333333333333334,
      "loss": 1.6657,
      "step": 110
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 5.272132873535156,
      "learning_rate": 0.00017076923076923077,
      "loss": 1.6809,
      "step": 120
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 8.888628005981445,
      "learning_rate": 0.00016820512820512823,
      "loss": 1.3864,
      "step": 130
    },
    {
      "epoch": 0.8974358974358975,
      "grad_norm": 8.873526573181152,
      "learning_rate": 0.00016564102564102566,
      "loss": 1.6213,
      "step": 140
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 6.733978748321533,
      "learning_rate": 0.0001630769230769231,
      "loss": 1.5004,
      "step": 150
    },
    {
      "epoch": 1.0256410256410255,
      "grad_norm": 6.114766597747803,
      "learning_rate": 0.00016051282051282053,
      "loss": 1.6209,
      "step": 160
    },
    {
      "epoch": 1.0897435897435896,
      "grad_norm": 7.45341157913208,
      "learning_rate": 0.00015794871794871796,
      "loss": 1.5727,
      "step": 170
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 6.25515079498291,
      "learning_rate": 0.0001553846153846154,
      "loss": 1.2438,
      "step": 180
    },
    {
      "epoch": 1.217948717948718,
      "grad_norm": 8.081328392028809,
      "learning_rate": 0.00015282051282051282,
      "loss": 1.3412,
      "step": 190
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 5.982475757598877,
      "learning_rate": 0.00015025641025641026,
      "loss": 1.292,
      "step": 200
    },
    {
      "epoch": 1.3461538461538463,
      "grad_norm": 6.256908416748047,
      "learning_rate": 0.00014769230769230772,
      "loss": 1.2028,
      "step": 210
    },
    {
      "epoch": 1.4102564102564101,
      "grad_norm": 7.6265459060668945,
      "learning_rate": 0.00014512820512820512,
      "loss": 1.1803,
      "step": 220
    },
    {
      "epoch": 1.4743589743589745,
      "grad_norm": 7.587664604187012,
      "learning_rate": 0.00014256410256410258,
      "loss": 1.6289,
      "step": 230
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 5.168005466461182,
      "learning_rate": 0.00014,
      "loss": 1.0564,
      "step": 240
    },
    {
      "epoch": 1.6025641025641026,
      "grad_norm": 7.691303730010986,
      "learning_rate": 0.00013743589743589745,
      "loss": 1.4381,
      "step": 250
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 6.955212116241455,
      "learning_rate": 0.00013487179487179488,
      "loss": 1.3995,
      "step": 260
    },
    {
      "epoch": 1.7307692307692308,
      "grad_norm": 7.657251834869385,
      "learning_rate": 0.0001323076923076923,
      "loss": 1.3705,
      "step": 270
    },
    {
      "epoch": 1.7948717948717947,
      "grad_norm": 7.084872722625732,
      "learning_rate": 0.00012974358974358975,
      "loss": 1.0605,
      "step": 280
    },
    {
      "epoch": 1.858974358974359,
      "grad_norm": 10.386966705322266,
      "learning_rate": 0.00012717948717948718,
      "loss": 1.1115,
      "step": 290
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 7.449010848999023,
      "learning_rate": 0.00012487179487179488,
      "loss": 1.5839,
      "step": 300
    },
    {
      "epoch": 1.9871794871794872,
      "grad_norm": 7.012335777282715,
      "learning_rate": 0.00012230769230769231,
      "loss": 1.2392,
      "step": 310
    },
    {
      "epoch": 2.051282051282051,
      "grad_norm": 5.824726104736328,
      "learning_rate": 0.00011974358974358975,
      "loss": 1.0705,
      "step": 320
    },
    {
      "epoch": 2.1153846153846154,
      "grad_norm": 8.88883113861084,
      "learning_rate": 0.00011717948717948719,
      "loss": 1.0811,
      "step": 330
    },
    {
      "epoch": 2.1794871794871793,
      "grad_norm": 9.075477600097656,
      "learning_rate": 0.00011461538461538461,
      "loss": 1.6973,
      "step": 340
    },
    {
      "epoch": 2.2435897435897436,
      "grad_norm": 9.458526611328125,
      "learning_rate": 0.00011205128205128206,
      "loss": 0.9226,
      "step": 350
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 8.311911582946777,
      "learning_rate": 0.0001094871794871795,
      "loss": 0.9698,
      "step": 360
    },
    {
      "epoch": 2.371794871794872,
      "grad_norm": 8.523500442504883,
      "learning_rate": 0.00010692307692307692,
      "loss": 1.1225,
      "step": 370
    },
    {
      "epoch": 2.435897435897436,
      "grad_norm": 6.0786542892456055,
      "learning_rate": 0.00010435897435897437,
      "loss": 1.2552,
      "step": 380
    },
    {
      "epoch": 2.5,
      "grad_norm": 7.409440994262695,
      "learning_rate": 0.00010179487179487179,
      "loss": 0.9559,
      "step": 390
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 9.151938438415527,
      "learning_rate": 9.923076923076923e-05,
      "loss": 1.4287,
      "step": 400
    },
    {
      "epoch": 2.628205128205128,
      "grad_norm": 6.646138668060303,
      "learning_rate": 9.666666666666667e-05,
      "loss": 1.3272,
      "step": 410
    },
    {
      "epoch": 2.6923076923076925,
      "grad_norm": 9.19288444519043,
      "learning_rate": 9.41025641025641e-05,
      "loss": 0.9579,
      "step": 420
    },
    {
      "epoch": 2.7564102564102564,
      "grad_norm": 10.229447364807129,
      "learning_rate": 9.153846153846155e-05,
      "loss": 0.9971,
      "step": 430
    },
    {
      "epoch": 2.8205128205128203,
      "grad_norm": 7.981417179107666,
      "learning_rate": 8.897435897435898e-05,
      "loss": 1.153,
      "step": 440
    },
    {
      "epoch": 2.8846153846153846,
      "grad_norm": 6.243329048156738,
      "learning_rate": 8.641025641025642e-05,
      "loss": 0.8236,
      "step": 450
    },
    {
      "epoch": 2.948717948717949,
      "grad_norm": 7.106440544128418,
      "learning_rate": 8.384615384615386e-05,
      "loss": 0.9844,
      "step": 460
    },
    {
      "epoch": 3.0128205128205128,
      "grad_norm": 5.336423397064209,
      "learning_rate": 8.128205128205129e-05,
      "loss": 0.9953,
      "step": 470
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 9.324999809265137,
      "learning_rate": 7.871794871794872e-05,
      "loss": 0.8339,
      "step": 480
    },
    {
      "epoch": 3.141025641025641,
      "grad_norm": 10.013511657714844,
      "learning_rate": 7.615384615384616e-05,
      "loss": 0.9822,
      "step": 490
    },
    {
      "epoch": 3.2051282051282053,
      "grad_norm": 11.972638130187988,
      "learning_rate": 7.35897435897436e-05,
      "loss": 0.9056,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 780,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 135940018065408.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
