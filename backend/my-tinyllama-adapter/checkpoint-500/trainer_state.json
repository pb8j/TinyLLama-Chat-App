{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.358695652173913,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02717391304347826,
      "grad_norm": 1.858280062675476,
      "learning_rate": 0.00019978260869565217,
      "loss": 2.9263,
      "step": 10
    },
    {
      "epoch": 0.05434782608695652,
      "grad_norm": 3.812354803085327,
      "learning_rate": 0.0001995380434782609,
      "loss": 3.0221,
      "step": 20
    },
    {
      "epoch": 0.08152173913043478,
      "grad_norm": 3.969658613204956,
      "learning_rate": 0.0001992663043478261,
      "loss": 2.4169,
      "step": 30
    },
    {
      "epoch": 0.10869565217391304,
      "grad_norm": 6.3559889793396,
      "learning_rate": 0.0001989945652173913,
      "loss": 2.0587,
      "step": 40
    },
    {
      "epoch": 0.1358695652173913,
      "grad_norm": 4.14518928527832,
      "learning_rate": 0.00019880434782608696,
      "loss": 1.8471,
      "step": 50
    },
    {
      "epoch": 0.16304347826086957,
      "grad_norm": 6.662506580352783,
      "learning_rate": 0.00019853260869565217,
      "loss": 2.1131,
      "step": 60
    },
    {
      "epoch": 0.19021739130434784,
      "grad_norm": 4.655934810638428,
      "learning_rate": 0.0001982608695652174,
      "loss": 1.6704,
      "step": 70
    },
    {
      "epoch": 0.21739130434782608,
      "grad_norm": 9.094929695129395,
      "learning_rate": 0.0001979891304347826,
      "loss": 1.6821,
      "step": 80
    },
    {
      "epoch": 0.24456521739130435,
      "grad_norm": 4.5194172859191895,
      "learning_rate": 0.00019771739130434784,
      "loss": 1.5413,
      "step": 90
    },
    {
      "epoch": 0.2717391304347826,
      "grad_norm": 14.408817291259766,
      "learning_rate": 0.00019744565217391305,
      "loss": 1.574,
      "step": 100
    },
    {
      "epoch": 0.29891304347826086,
      "grad_norm": 7.112241744995117,
      "learning_rate": 0.00019717391304347828,
      "loss": 1.3409,
      "step": 110
    },
    {
      "epoch": 0.32608695652173914,
      "grad_norm": 7.8925700187683105,
      "learning_rate": 0.0001969021739130435,
      "loss": 1.5467,
      "step": 120
    },
    {
      "epoch": 0.3532608695652174,
      "grad_norm": 6.134781360626221,
      "learning_rate": 0.0001966304347826087,
      "loss": 1.6731,
      "step": 130
    },
    {
      "epoch": 0.3804347826086957,
      "grad_norm": 10.355749130249023,
      "learning_rate": 0.00019635869565217393,
      "loss": 1.2999,
      "step": 140
    },
    {
      "epoch": 0.4076086956521739,
      "grad_norm": 4.096418380737305,
      "learning_rate": 0.00019608695652173914,
      "loss": 1.5674,
      "step": 150
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 4.768747806549072,
      "learning_rate": 0.00019581521739130435,
      "loss": 1.1745,
      "step": 160
    },
    {
      "epoch": 0.46195652173913043,
      "grad_norm": 6.453281879425049,
      "learning_rate": 0.00019554347826086958,
      "loss": 1.3976,
      "step": 170
    },
    {
      "epoch": 0.4891304347826087,
      "grad_norm": 4.45206356048584,
      "learning_rate": 0.0001952717391304348,
      "loss": 1.5724,
      "step": 180
    },
    {
      "epoch": 0.5163043478260869,
      "grad_norm": 5.2901411056518555,
      "learning_rate": 0.000195,
      "loss": 1.5382,
      "step": 190
    },
    {
      "epoch": 0.5434782608695652,
      "grad_norm": 4.825442314147949,
      "learning_rate": 0.00019472826086956523,
      "loss": 1.4633,
      "step": 200
    },
    {
      "epoch": 0.5706521739130435,
      "grad_norm": 6.178434371948242,
      "learning_rate": 0.00019445652173913044,
      "loss": 1.4216,
      "step": 210
    },
    {
      "epoch": 0.5978260869565217,
      "grad_norm": 7.09343957901001,
      "learning_rate": 0.00019418478260869567,
      "loss": 1.4035,
      "step": 220
    },
    {
      "epoch": 0.625,
      "grad_norm": 7.159855842590332,
      "learning_rate": 0.00019391304347826088,
      "loss": 1.4828,
      "step": 230
    },
    {
      "epoch": 0.6521739130434783,
      "grad_norm": 5.902719974517822,
      "learning_rate": 0.00019364130434782611,
      "loss": 1.2125,
      "step": 240
    },
    {
      "epoch": 0.6793478260869565,
      "grad_norm": 4.84725284576416,
      "learning_rate": 0.00019336956521739132,
      "loss": 1.4477,
      "step": 250
    },
    {
      "epoch": 0.7065217391304348,
      "grad_norm": 4.909605026245117,
      "learning_rate": 0.00019309782608695653,
      "loss": 1.217,
      "step": 260
    },
    {
      "epoch": 0.7336956521739131,
      "grad_norm": 6.655997276306152,
      "learning_rate": 0.00019282608695652176,
      "loss": 1.297,
      "step": 270
    },
    {
      "epoch": 0.7608695652173914,
      "grad_norm": 4.5640764236450195,
      "learning_rate": 0.00019255434782608697,
      "loss": 1.4114,
      "step": 280
    },
    {
      "epoch": 0.7880434782608695,
      "grad_norm": 4.893315315246582,
      "learning_rate": 0.00019228260869565218,
      "loss": 1.086,
      "step": 290
    },
    {
      "epoch": 0.8152173913043478,
      "grad_norm": 9.92303466796875,
      "learning_rate": 0.0001920108695652174,
      "loss": 1.4338,
      "step": 300
    },
    {
      "epoch": 0.842391304347826,
      "grad_norm": 7.21193265914917,
      "learning_rate": 0.00019173913043478262,
      "loss": 1.2129,
      "step": 310
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 7.024837970733643,
      "learning_rate": 0.00019146739130434783,
      "loss": 1.2183,
      "step": 320
    },
    {
      "epoch": 0.8967391304347826,
      "grad_norm": 6.16318941116333,
      "learning_rate": 0.00019119565217391303,
      "loss": 1.0701,
      "step": 330
    },
    {
      "epoch": 0.9239130434782609,
      "grad_norm": 6.199466228485107,
      "learning_rate": 0.00019092391304347827,
      "loss": 1.2121,
      "step": 340
    },
    {
      "epoch": 0.9510869565217391,
      "grad_norm": 5.623912811279297,
      "learning_rate": 0.00019065217391304348,
      "loss": 1.3395,
      "step": 350
    },
    {
      "epoch": 0.9782608695652174,
      "grad_norm": 6.265106201171875,
      "learning_rate": 0.0001903804347826087,
      "loss": 1.2074,
      "step": 360
    },
    {
      "epoch": 1.0054347826086956,
      "grad_norm": 7.836062431335449,
      "learning_rate": 0.00019010869565217392,
      "loss": 1.1569,
      "step": 370
    },
    {
      "epoch": 1.0326086956521738,
      "grad_norm": 6.503505229949951,
      "learning_rate": 0.00018983695652173915,
      "loss": 0.9372,
      "step": 380
    },
    {
      "epoch": 1.059782608695652,
      "grad_norm": 6.2892985343933105,
      "learning_rate": 0.00018956521739130436,
      "loss": 1.1895,
      "step": 390
    },
    {
      "epoch": 1.0869565217391304,
      "grad_norm": 7.21104097366333,
      "learning_rate": 0.0001892934782608696,
      "loss": 1.4854,
      "step": 400
    },
    {
      "epoch": 1.1141304347826086,
      "grad_norm": 7.502607345581055,
      "learning_rate": 0.0001890217391304348,
      "loss": 1.0431,
      "step": 410
    },
    {
      "epoch": 1.141304347826087,
      "grad_norm": 5.04808235168457,
      "learning_rate": 0.00018875,
      "loss": 1.1058,
      "step": 420
    },
    {
      "epoch": 1.1684782608695652,
      "grad_norm": 4.976306915283203,
      "learning_rate": 0.00018847826086956524,
      "loss": 0.9103,
      "step": 430
    },
    {
      "epoch": 1.1956521739130435,
      "grad_norm": 8.628564834594727,
      "learning_rate": 0.00018820652173913045,
      "loss": 1.1287,
      "step": 440
    },
    {
      "epoch": 1.2228260869565217,
      "grad_norm": 16.884870529174805,
      "learning_rate": 0.00018793478260869566,
      "loss": 0.9912,
      "step": 450
    },
    {
      "epoch": 1.25,
      "grad_norm": 5.307351589202881,
      "learning_rate": 0.00018766304347826086,
      "loss": 0.9098,
      "step": 460
    },
    {
      "epoch": 1.2771739130434783,
      "grad_norm": 8.836557388305664,
      "learning_rate": 0.0001873913043478261,
      "loss": 0.8656,
      "step": 470
    },
    {
      "epoch": 1.3043478260869565,
      "grad_norm": 8.308188438415527,
      "learning_rate": 0.0001871195652173913,
      "loss": 1.3327,
      "step": 480
    },
    {
      "epoch": 1.3315217391304348,
      "grad_norm": 6.589860916137695,
      "learning_rate": 0.0001868478260869565,
      "loss": 0.8747,
      "step": 490
    },
    {
      "epoch": 1.358695652173913,
      "grad_norm": 3.953298807144165,
      "learning_rate": 0.00018657608695652175,
      "loss": 0.8456,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 7360,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 145136490467328.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
